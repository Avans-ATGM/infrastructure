---
# Python 3 support
pip_virtualenv_command: /usr/bin/python3 -m virtualenv # usegalaxy_eu.certbot, usegalaxy_eu.tiaas2, galaxyproject.galaxy
certbot_virtualenv_package_name: python3-virtualenv    # usegalaxy_eu.certbot
pip_package: python3-pip                               # geerlingguy.pip

# PostgreSQL
postgresql_objects_users:
  - name: galaxy
  - name: telegraf
  - name: tiaas
postgresql_objects_databases:
  - name: galaxy
    owner: galaxy
postgresql_objects_privileges:
  - database: galaxy
    roles: telegraf
    privs: SELECT
    objs: ALL_IN_SCHEMA
  - database: galaxy
    roles: tiaas
    objs: galaxy_user,galaxy_session,job,history,workflow,workflow_invocation
    type: table
    privs: SELECT
  - database: galaxy
    roles: tiaas
    objs: user_group_association,galaxy_group,role,group_role_association
    type: table
    privs: SELECT,INSERT
  - database: galaxy
    roles: tiaas
    objs: role_id_seq,galaxy_group_id_seq,group_role_association_id_seq,user_group_association_id_seq
    type: sequence
    privs: USAGE,SELECT

# PostgreSQL Backups
postgresql_backup_dir: /data/backups
postgresql_backup_local_dir: "{{ '~postgres' | expanduser }}/backups"

# Galaxy
galaxy_create_user: true
galaxy_separate_privileges: true
galaxy_manage_paths: true
galaxy_layout: root-dir
galaxy_root: /srv/galaxy
galaxy_user: {name: galaxy, shell: /bin/bash}
galaxy_commit_id: release_22.01
galaxy_config_style: yaml
galaxy_force_checkout: true
galaxy_backup_configfiles: false

file_path: /data
#possible change conda envs in next semester when galaxy server is used less? perhaps reinstalling items due hardcoding???????
#miniconda_prefix: "{{ file_path }}/dependencies/_conda"
miniconda_prefix: "{{ galaxy_tool_dependency_dir }}/_conda"
miniconda_version: "4.7.12"
miniconda_manage_dependencies: false

galaxy_config:
  galaxy:
    brand: "ðŸ§¬ATLSðŸ”¬{{ brand_extra | default() }}"
    admin_users: es.rasche@avans.nl,bk.sanders@avans.nl,m.zhou1@avans.nl,dl.vrins@avans.nl
    database_connection: "postgresql:///galaxy?host=/var/run/postgresql"
    check_migrate_tools: false
    # due to storage room is the conde enviorments and dependencies changed from location
    #tool_data_path: "{{ galaxy_mutable_data_dir }}/tool-data"
    tool_data_path: "{{ file_path }}/galaxy/var/tool-data"
    data_dir: "{{ galaxy_mutable_data_dir }}" # I think this is fixed in more recent role versions.
    auth_config_file: "{{ galaxy_config_dir }}/auth_conf.xml"
    job_config_file: "{{ galaxy_config_dir }}/job_conf.xml"
    id_secret: "{{ id_secret }}"
    tool_data_table_config_path: /cvmfs/data.galaxyproject.org/byhand/location/tool_data_table_conf.xml,/cvmfs/data.galaxyproject.org/managed/location/tool_data_table_conf.xml
    # TODO: install conda, because this speeds up installation a LOT.
    #conda_exec: '{{ miniconda_prefix }}/bin/mamba'
    object_store_store_by: uuid
    #dependency_resolvers_config_file: "{{ galaxy_config_dir }}/dependency_resolvers_conf.xml"
    #containers_resolvers_config_file: "{{ galaxy_config_dir }}/container_resolvers_conf.xml"
    statsd_host: localhost
    statsd_influxdb: true
    # todo: GAT
    trs_servers_config_file: "{{ galaxy_config_dir }}/trs_servers_conf.yml"
    aws_estimate: true
    job_working_directory: /data/jobs
    allow_path_paste: true
    database_engine_option_server_side_cursors: true
    slow_query_log_threshold: 5
    enable_per_request_sql_debugging: true
    #watch_tools: 'auto'
    watch_job_rules: 'polling'
    nginx_x_accel_redirect_base: /_x_accel_redirect
    sanitize_all_html: false
    serve_xss_vulnerable_mimetypes: true
    error_email_to: galaxy@galaxy.bioinformatics-atgm.nl
    library_import_dir: /data/library
    show_welcome_with_login: true
    #expose_user_name: true
    enable_quotas: true
    expose_dataset_path: true
    expose_potentially_sensitive_job_metrics: true
    outputs_to_working_directory: true
    cleanup_job: always
    allow_user_deletion: true
    allow_user_impersonation: true
    object_store_config_file: "{{ galaxy_config_dir }}/object_store_conf.xml"
    email_domain_allowlist_file: "{{ galaxy_config_dir }}/email_allowlist.txt"
    interactivetools_enable: true
    interactivetools_map: "{{ gie_proxy_sessions_path }}"
    galaxy_infrastructure_url: "https://{{ inventory_hostname }}/"
  uwsgi:
    socket: 127.0.0.1:4001
    buffer-size: 16384
    processes: 1
    threads: 4
    offload-threads: 2
    static-map:
      - /static={{ galaxy_server_dir }}/static
      - /favicon.ico={{ galaxy_server_dir }}/static/favicon.ico
    static-safe: client/galaxy/images
    master: true
    virtualenv: "{{ galaxy_venv_dir }}"
    pythonpath: "{{ galaxy_server_dir }}/lib"
    module: galaxy.webapps.galaxy.buildapp:uwsgi_app()
    thunder-lock: true
    die-on-term: true
    hook-master-start:
      - unix_signal:2 gracefully_kill_them_all
      - unix_signal:15 gracefully_kill_them_all
    py-call-osafterfork: true
    enable-threads: true
    mule:
      - lib/galaxy/main.py
      - lib/galaxy/main.py
    farm: job-handlers:1,2

galaxy_tool_config_files:
  - "{{ galaxy_server_dir }}/config/tool_conf.xml.sample"
  - "{{ galaxy_config_dir }}/tool_conf_interactive.xml"

galaxy_config_templates:
  - src: templates/galaxy/config/email_allowlist.txt
    dest: "{{ galaxy_config.galaxy.email_domain_allowlist_file }}"
  - src: templates/galaxy/config/job_conf.xml.j2
    dest: "{{ galaxy_config.galaxy.job_config_file }}"
  #- src: templates/galaxy/config/container_resolvers_conf.xml.j2
    #dest: "{{ galaxy_config.galaxy.containers_resolvers_config_file }}"
  - src: templates/galaxy/config/welcome.html
    dest: "{{ galaxy_mutable_data_dir }}/welcome.html"
  - src: templates/galaxy/config/auth_conf.xml
    dest: "{{ galaxy_config.galaxy.auth_config_file }}"
  - src: templates/galaxy/config/object_store_conf.xml
    dest: "{{ galaxy_config.galaxy.object_store_config_file }}"
  - src: templates/galaxy/config/tool_conf_interactive.xml.j2
    dest: "{{ galaxy_config_dir }}/tool_conf_interactive.xml"
  - src: templates/galaxy/config/pulsar_app.yml.j2
    dest: "{{ galaxy_config_dir }}/pulsar_app.yml"

galaxy_config_files:
#- src: files/galaxy/config/dependency_resolvers_conf.xml
  #dest: "{{ galaxy_config.galaxy.dependency_resolvers_config_file }}"
  #group_vars/sn06.yml
- src: "files/galaxy/config/trs_servers_conf.yml"
  dest: "{{ galaxy_config.galaxy.trs_servers_config_file }}"

#custome galaxy tools
galaxy_local_tools:
  - extract_identifiers.xml
# systemd
galaxy_systemd_mode: mule
galaxy_zergpool_listen_addr: 127.0.0.1:8080
galaxy_restart_handler_name: "Restart Galaxy"

# NGINX
nginx_selinux_allow_local_connections: true
nginx_servers:
  - redirect-ssl
nginx_ssl_servers:
  - galaxy
  - galaxy-gie-proxy

nginx_enable_default_server: false
nginx_conf_http:
  client_max_body_size: 1g

# Jenkins
jenkins_http_port: 4000
jenkins_admin_username: admin
# Please change at least the password to something more suitable
jenkins_admin_password: "{{ jenkins_password }}"
jenkins_url_prefix: /jenkins
jenkins_plugins:
- matrix-auth
- shiningpanda
- git
- credentials-binding
- simple-theme-plugin
- embeddable-build-status

# OS env
os_desktop_enable: true
os_env_umask: "022"
os_auth_pw_max_age: 99999
os_auth_retries: 10

# HTCondor
condor_roles:
    - execute
    - central-manager
    - submit

# Monitoring
custom_telegraf_env: "/usr/bin/env GDPR_MODE=1 PGUSER=galaxy GALAXY_ROOT=/srv/galaxy/server GALAXY_CONFIG_FILE=/srv/galaxy/config/galaxy.yml GXADMIN_PYTHON=/srv/galaxy/venv/bin/python"
telegraf_plugins_extra:
  postgres:
    plugin: "postgresql"
    config:
      - address = "{{ galaxy_config.galaxy.database_connection }}"
      - databases = ["galaxy"]

  listen_galaxy_routes:
    plugin: "statsd"
    config:
      - service_address = ":8125"
      - percentiles = [90]
      - metric_separator = "."
      - allowed_pending_messages = 10000
      - percentile_limit = 100

  docker:
    plugin: "docker"

  monitor_galaxy_queue:
    plugin: "exec"
    config:
      - commands = ["/usr/bin/env PGDATABASE=galaxy /usr/local/bin/gxadmin iquery queue-overview --short-tool-id"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "15s"

  monitor_condor_queue:
    plugin: "exec"
    config:
      - commands = ["sudo /usr/bin/monitor-condor-queue"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "1m"

  monitor_condor_util:
    plugin: "exec"
    config:
      - commands = ["sudo /usr/bin/monitor-condor-utilisation"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "1m"

  monitor_nfsstat:
    plugin: "exec"
    config:
      - commands = ["/usr/bin/nfsstat-influx"]
      - timeout = "10s"
      - data_format = "influx"
      - interval = "15s"

  # Some custom galaxy monitoring stuff
  galaxy_uploaded:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery upload-gb-in-past-hour"]
      - timeout = "60s"
      - data_format = "influx"
      - interval = "1h"
  galaxy_lastlog:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin uwsgi lastlog"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "15s"
  galaxy_jobs_queued:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery jobs-queued"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_jobs_queued_internal:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery jobs-queued-internal-by-handler"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_workflow:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery workflow-invocation-status"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_workflow_totals:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin iquery workflow-invocation-totals"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"
  galaxy_active_users:
    plugin: "exec"
    config:
      - commands = ["{{ custom_telegraf_env }} /usr/bin/gxadmin uwsgi active-users"]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"

  monitor_ssl:
    plugin: x509_cert
    config:
      - 'sources = ["https://galaxy.atgm.avans.nl:443", "https://test-galaxy.atgm.avans.nl:443"]'

  postgres_extra:
    plugin: "exec"
    config:
      - commands = [
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-cache-hit",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-index-size",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-index-usage",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-table-bloat",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-table-size",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-unused-indexes",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-vacuum-stats",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-stat-bgwriter",
          "{{ custom_telegraf_env }} /usr/bin/gxadmin iquery pg-stat-user-tables",
        ]
      - timeout = "15s"
      - data_format = "influx"
      - interval = "1m"

monitor_condor: true
monitor_condor_split_util: true

# TIaaS
tiaas_dir: /srv/tiaas
tiaas_user: tiaas
tiaas_group: tiaas
tiaas_admin_user: admin
tiaas_admin_pass: "{{ secret_tiaas_admin_pw }}"
tiaas_templates_dir: tiaas/html
tiaas_show_advertising: false
tiaas_retain_contact_require_consent: false

tiaas_info:
  owner: Avans
  owner_email: bioinformatics-team@bioinformatics-atgm.nl
  owner_site: "https://{{ inventory_hostname }}"
  domain: "{{ inventory_hostname }}"

tiaas_other_config: |
  TIAAS_EXPOSE_USERNAME = True

# NFS
nfs_exports:
- "/srv/galaxy 145.48.205.36(rw,sync,no_root_squash,no_subtree_check) 145.48.205.37(rw,sync,no_root_squash,no_subtree_check) 145.48.205.25(rw,sync,no_root_squash,no_subtree_check)"
- "/data 145.48.205.36(rw,sync,no_root_squash,no_subtree_check) 145.48.205.37(rw,sync,no_root_squash,no_subtree_check) 145.48.205.25(rw,sync,no_root_squash,no_subtree_check)"

# Interactive Tools
docker_install_compose: false
docker_users:
  - "{{ galaxy_user.name }}"
  - hexylena
  - telegraf


gie_proxy_dir: /srv/gie-proxy/proxy
gie_proxy_setup_nodejs: nodeenv
gie_proxy_nodejs_version: "16.13.1"
gie_proxy_virtualenv: /srv/gie-proxy/venv
gie_proxy_setup_service: systemd
gie_proxy_port: 4002
gie_proxy_verbose: true
gie_proxy_sessions_path: "{{ galaxy_mutable_data_dir }}/interactivetools_map.sqlite"

# RabbitMQ
rabbitmq_version: 3.8.16-1
rabbitmq_plugins: rabbitmq_management

rabbitmq_config:
- rabbit:
  - tcp_listeners:
    - "'127.0.0.1'": 5672
  - ssl_listeners:
    - "'0.0.0.0'": 5671
  - ssl_options:
     - cacertfile: "/etc/ssl/certs/{{ openssl_domains[0] }}.crt"
     - certfile: "/etc/ssl/certs/{{ openssl_domains[0] }}.crt"
     - keyfile: "/etc/ssl/private/{{ openssl_domains[0] }}.pem"
     - fail_if_no_peer_cert: 'false'

rabbitmq_vhosts:
  - /pulsar/Isengard
  #- /pulsar/Asgard
  #- /pulsar/Midgard

rabbitmq_users:
  - user: admin
    password: "{{ pulsar_password }}"
    tags: administrator
    vhost: /
  - user: Isengard
    password: "{{ pulsar_password }}"
    tags: worker
    vhost: /pulsar/Isengard
  #- user: Asgard
  #  password: "{{ pulsar_password }}"
  #  tags: worker
  #  vhost: /pulsar/Asgard
  #- user: Midgard
  #  password: "{{ pulsar_password }}"
  #  tags: worker
  #  vhost: /pulsar/Midgard

