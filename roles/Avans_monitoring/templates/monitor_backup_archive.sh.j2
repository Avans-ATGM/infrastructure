
date_month=$(journalctl -u student_project_backup.service |tail -1 | cut -d " " -f 1)
date_day=$(journalctl -u student_project_backup.service |tail -1 | cut -d " " -f 2)
date=$(date --date="$(printf "01 %s"$mydate)" +"%Y-%m"-$date_day )
date1=$(date --date="next day" +%y-%m-%d)
timestamp=$(date +%s%N)

N_success=0
exit_status=1
N_pruning=0
N_databases_created=0
N_fail_error=0

Original_size_GB=$(journalctl -u student_project_backup.service --since=$date  --until=$date1 | grep "Size archives on {{ backup_archive_addres_1 }}" | tail -1 | xargs |  cut -d ":" -f 7 |  cut -d " " -f 2| cut -d "." -f 1)
Compressed_size_GB=$(journalctl -u student_project_backup.service --since=$date  --until=$date1 | grep "Size archives on {{ backup_archive_addres_1 }}" | tail -1 | xargs |  cut -d ":" -f 7 |  cut -d " " -f 4| cut -d "." -f 1)
Deduplicated_size_GB=$(journalctl -u student_project_backup.service --since=$date  --until=$date1 | grep "Size archives on {{ backup_archive_addres_1 }}" | tail -1 | xargs |  cut -d ":" -f 7 |  cut -d " " -f 6| cut -d "." -f 1)

Perc_compressed_size=$(echo "$Compressed_size_GB/1000" | bc -l | awk '{printf "%f", $0}') 
echo "borg_backup,Host={{ backup_archive_addres_1 }} Pruned_archives=${N_pruning}i,Number_of_databases_created=${N_databases_created}i,succesfull_jobs=${N_success}i,errors=${N_fail_error}i,total_archives=${T_archives}i,exit_status=${exit_status}i,original_size=${Original_size_GB}i,compressed_size=${Compressed_size_GB}i,de_duplicated_size=${Deduplicated_size_GB}i,Perc_compressed_size_gb=${Perc_compressed_size} $timestamp"
